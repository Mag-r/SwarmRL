{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:51:57.756420: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.20. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "\n",
    "from numba import cuda\n",
    "from flax import linen as nn\n",
    "\n",
    "from swarmrl.observables.car_image import CarImage\n",
    "from swarmrl.engine.car_benchmark import CarBenchmark\n",
    "from swarmrl.tasks.MPI_chain import ChainTask\n",
    "from swarmrl.trainers.global_continuous_trainer import (\n",
    "    GlobalContinuousTrainer as Trainer,\n",
    ")\n",
    "import optax\n",
    "import swarmrl as srl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dimension = 3\n",
    "\n",
    "\n",
    "class ActoCriticNet(nn.Module):\n",
    "    \"\"\"A simple dense model.\n",
    "    (batch,time,features)\n",
    "    When dense at beginning, probably flatten is required\n",
    "    \"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        # Define a scanned LSTM cell\n",
    "        self.ScanLSTM = nn.scan(\n",
    "            nn.OptimizedLSTMCell,\n",
    "            variable_broadcast=\"params\",\n",
    "            split_rngs={\"params\": False},\n",
    "            in_axes=1,\n",
    "            out_axes=1,\n",
    "        )\n",
    "        self.lstm = self.ScanLSTM(features=12)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, previous_actions, action, carry=None):\n",
    "        batch_size, sequence_length = x.shape[0], x.shape[1]\n",
    "\n",
    "        x = nn.Conv(features=12, kernel_size=(3, 3), strides=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = nn.Conv(features=12, kernel_size=(3, 3), strides=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = x.reshape((batch_size, sequence_length, -1))\n",
    "        x = nn.Dense(features=12)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = jnp.concatenate([x, previous_actions], axis=-1)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        # Initialize carry if it's not provided\n",
    "        if carry is None:\n",
    "            carry = self.lstm.initialize_carry(\n",
    "                jax.random.PRNGKey(0), x.shape[:1] + x.shape[2:]\n",
    "            )\n",
    "            print(\"Action Net: new carry initialized\")\n",
    "        carry, x = self.lstm(carry, x)\n",
    "        x = x.reshape((batch_size, -1))\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        actor = nn.Dense(features=12, name=\"Actor_1\")(x)\n",
    "        actor = nn.relu(actor)\n",
    "        actor = nn.LayerNorm()(actor)\n",
    "        actor = nn.Dense(features=12, name=\"Actor_2\")(actor)\n",
    "        actor = nn.relu(actor)\n",
    "        actor = nn.LayerNorm()(actor)\n",
    "\n",
    "        actor = nn.Dense(features=action_dimension * 2, name=\"Actor_3\")(actor)\n",
    "        actor = actor.at[:, 3:].set(jnp.log1p(jnp.exp(actor.at[:, 3:].get())))\n",
    "\n",
    "        if action is not None:\n",
    "            x = jnp.concatenate([x, action], axis=-1)\n",
    "            q_1 = nn.Dense(features=12)(x)\n",
    "            q_2 = nn.Dense(features=12)(x)\n",
    "            q_1 = nn.relu(q_1)\n",
    "            q_2 = nn.relu(q_2)\n",
    "            q_1 = nn.Dense(features=12)(q_1)\n",
    "            q_2 = nn.Dense(features=12)(q_2)\n",
    "            # q_1 = q_1 + x\n",
    "            # q_2 = q_2 + x\n",
    "            q_1 = nn.relu(q_1)\n",
    "            q_2 = nn.relu(q_2)\n",
    "            q_1 = nn.Dense(features=1)(q_1)\n",
    "            q_2 = nn.Dense(features=1)(q_2)\n",
    "        else:\n",
    "            q_1 = None\n",
    "            q_2 = None\n",
    "\n",
    "        return actor, q_1, q_2, carry\n",
    "\n",
    "\n",
    "class TargetNet(nn.Module):\n",
    "    def setup(self):\n",
    "        # Define a scanned LSTM cell\n",
    "        self.ScanLSTM = nn.scan(\n",
    "            nn.OptimizedLSTMCell,\n",
    "            variable_broadcast=\"params\",\n",
    "            split_rngs={\"params\": False},\n",
    "            in_axes=1,\n",
    "            out_axes=1,\n",
    "        )\n",
    "        self.lstm = self.ScanLSTM(features=12)\n",
    "\n",
    "    @nn.remat\n",
    "    @nn.compact\n",
    "    def __call__(self, x, previous_actions, action, carry=None):\n",
    "        batch_size, sequence_length = x.shape[0], x.shape[1]\n",
    "\n",
    "        x = nn.Conv(features=12, kernel_size=(3, 3), strides=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = nn.Conv(features=12, kernel_size=(3, 3), strides=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = x.reshape((batch_size, sequence_length, -1))\n",
    "        x = nn.Dense(features=12)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = jnp.concatenate([x, previous_actions], axis=-1)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        # Initialize carry if it's not provided\n",
    "        if carry is None:\n",
    "            carry = self.lstm.initialize_carry(\n",
    "                jax.random.PRNGKey(0), x.shape[:1] + x.shape[2:]\n",
    "            )\n",
    "            print(\"Action Net: new carry initialized\")\n",
    "        carry, x = self.lstm(carry, x)\n",
    "        x = x.reshape((batch_size, -1))\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = jnp.concatenate([x, action], axis=-1)\n",
    "\n",
    "        q_1 = nn.Dense(features=12)(x)\n",
    "        q_2 = nn.Dense(features=12)(x)\n",
    "        q_1 = nn.relu(q_1)\n",
    "        q_2 = nn.relu(q_2)\n",
    "        q_1 = nn.Dense(features=12)(q_1)\n",
    "        q_2 = nn.Dense(features=12)(q_2)\n",
    "        # q_1 = q_1 + x\n",
    "        # q_2 = q_2 + x\n",
    "        q_1 = nn.relu(q_1)\n",
    "        q_2 = nn.relu(q_2)\n",
    "        q_1 = nn.Dense(features=1)(q_1)\n",
    "        q_2 = nn.Dense(features=1)(q_2)\n",
    "        return q_1, q_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:51:59,355 - 2521701895.py - INFO - Initializing observables and tasks\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cuda.select_device(0)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(filename)s - %(levelname)s - %(message)s\\n\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\n",
    "resolution = 96\n",
    "learning_rate = 1e-3\n",
    "sequence_length = 4\n",
    "\n",
    "\n",
    "logger.info(\"Initializing observables and tasks\")\n",
    "obs = CarImage()\n",
    "\n",
    "# task = DummyTask(np.array([10000,10000,0]),target= np.array([5000,5000,0]))\n",
    "# print(f\"task initialized, with normalization = {task.get_normalization()}\", flush=True)\n",
    "task = ChainTask()\n",
    "\n",
    "actor_critic = ActoCriticNet()\n",
    "target = TargetNet()\n",
    "exploration_policy = srl.exploration_policies.GlobalOUExploration(\n",
    "    drift=0.2, volatility=0.3\n",
    ")\n",
    "\n",
    "# Define a sampling_strategy\n",
    "sampling_strategy = srl.sampling_strategies.ContinuousGaussianDistribution()\n",
    "# sampling_strategy = srl.sampling_strategies.ExpertKnowledge()\n",
    "# Value function to use\n",
    "value_function = srl.value_functions.TDReturnsSAC(gamma=0.99, standardize=True)\n",
    "\n",
    "network = srl.networks.ContinuousActionModel(\n",
    "    flax_model=actor_critic,\n",
    "    optimizer=optax.adam(learning_rate=learning_rate),\n",
    "    input_shape=(\n",
    "        10,\n",
    "        sequence_length,\n",
    "        resolution,\n",
    "        resolution,\n",
    "        1,\n",
    "    ),  # batch implicitly 1 ,time,H,W,channels for conv\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    exploration_policy=exploration_policy,\n",
    "    action_dimension=action_dimension,\n",
    "    deployment_mode=learning_rate == 0.0,\n",
    ")\n",
    "target_network = srl.networks.ContinuousTargetModel(\n",
    "    flax_model=target,\n",
    "    optimizer=optax.adam(learning_rate=learning_rate),\n",
    "    input_shape=(\n",
    "        10,\n",
    "        sequence_length,\n",
    "        resolution,\n",
    "        resolution,\n",
    "        1,\n",
    "    ),  # batch implicitly 1 ,time,H,W,channels for conv\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    exploration_policy=exploration_policy,\n",
    "    action_dimension=action_dimension,\n",
    "    deployment_mode=learning_rate == 0.0,\n",
    ")\n",
    "\n",
    "loss = srl.losses.SoftActorCriticGradientLoss(\n",
    "    value_function=value_function, learning_rate=learning_rate, minimum_entropy=-action_dimension\n",
    ")\n",
    "\n",
    "protocol = srl.agents.MPIActorCriticAgent(\n",
    "    particle_type=0,\n",
    "    network=network,\n",
    "    target_network=target_network,\n",
    "    task=task,\n",
    "    observable=obs,\n",
    "    loss=loss,\n",
    ")\n",
    "# Initialize the simulation system\n",
    "total_reward = []\n",
    "for j in range(1, 100):\n",
    "    system_runner = CarBenchmark()\n",
    "\n",
    "    # learning_rate = np.random.rand() * np.power(10.0, np.random.randint(-16, -3))\n",
    "\n",
    "    rl_trainer = Trainer([protocol])\n",
    "    print(f\"Start training, with learning rate {learning_rate}\", flush=True)\n",
    "    reward = rl_trainer.perform_rl_training(system_runner, 40, 10)\n",
    "    total_reward.append(reward)\n",
    "    logger.info(\n",
    "        f\"Resetting System, reward for this episode: {np.sum(reward)}, average reward is: {np.sum(total_reward)/j}, with learning rate: {learning_rate}\"\n",
    "    )\n",
    "np.save(\"total_reward.npy\", total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
